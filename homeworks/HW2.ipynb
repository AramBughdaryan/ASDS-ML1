{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYGbp2BJviXl"
   },
   "source": [
    "The deadline for this homework is on **07.03.2025 18:29** (right before the practice session). After completing the exercises, you should\n",
    "\n",
    "1. Download this file into your computer (`File` $\\to$ `Download .ipynb`)\n",
    "\n",
    "2. Name the file in the following way *HWx_NameSurname* (for example `HW2_NshanPotikyan.ipynb`)\n",
    "\n",
    "4. Submit the file via the e-learning environment.\n",
    "\n",
    "**Note** if you do not follow any of the above conditions, your homework will not be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsXZ3y2Dx9UM"
   },
   "source": [
    "**Problem.** During the practice session we tried to build a binary classifier on the titanic dataset that would predict whether a passenger will survive or not.\n",
    "\n",
    "* In this homework, you need to take the same dataset but this time you need to try the 3 different algorithm families on the given problem\n",
    "  * KNN\n",
    "  * Naive Bayes\n",
    "  * Decision Trees\n",
    "\n",
    "* Split the training dataset into train/test parts, so that you can evaluate the performance of the best approach at the end (use random_state=42, train=80%, test=20% splits). **You should not used the test set when looking for the best algorithm/hyper-parameters.**\n",
    "\n",
    "* Try leaving out unimportant features from the data (use feature importances returned from the decision tree).\n",
    "\n",
    "* Make use of sklearn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) to construct the different approaches.\n",
    "\n",
    "* Use hyper-parameter tuning (GridSearchCV) to find the best combination of parameters for each algorithm.\n",
    "\n",
    "* Evaluate the model performance in terms of the accuracy score.\n",
    "\n",
    "* Report the accuracy score of the best approach on the test dataset.\n",
    "\n",
    "Your grade will be based on\n",
    "\n",
    "* whether you have done all the modelling steps correctly\n",
    "* how many things you have tried\n",
    "* how good your final model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import graphviz   # will be used to visualize the trees\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass     Sex   Age  Siblings/Spouses Aboard  \\\n",
      "0         0       3    male  22.0                        1   \n",
      "1         1       1  female  38.0                        1   \n",
      "2         1       3  female  26.0                        0   \n",
      "3         1       1  female  35.0                        1   \n",
      "4         0       3    male  35.0                        0   \n",
      "\n",
      "   Parents/Children Aboard     Fare  \n",
      "0                        0   7.2500  \n",
      "1                        0  71.2833  \n",
      "2                        0   7.9250  \n",
      "3                        0  53.1000  \n",
      "4                        0   8.0500  \n"
     ]
    }
   ],
   "source": [
    "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "titanic_df.drop(['Name'], axis=1, inplace=True)\n",
    "titanic_df_ = pd.get_dummies(titanic_df, columns=['Sex'], drop_first=True)\n",
    "X = titanic_df_.drop('Survived', axis=1)\n",
    "y = titanic_df_['Survived']\n",
    "print(titanic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid, y_train_valid, test_size=0.1, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in the train set:\n",
      " Survived\n",
      "0    393\n",
      "1    245\n",
      "Name: count, dtype: int64\n",
      "Class distribution in the test set:\n",
      " Survived\n",
      "0    111\n",
      "1     67\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution in the train set:\\n\", y_train.value_counts())\n",
    "print(\"Class distribution in the test set:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.096246   0.25610992 0.05063575 0.03162374 0.2755896  0.28979498]\n",
      "                   Feature  Importance\n",
      "5                 Sex_male    0.289795\n",
      "4                     Fare    0.275590\n",
      "1                      Age    0.256110\n",
      "0                   Pclass    0.096246\n",
      "2  Siblings/Spouses Aboard    0.050636\n",
      "3  Parents/Children Aboard    0.031624\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "print(importances)\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns,\n",
    "                                      'Importance': importances})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance',\n",
    "                                                          ascending=False)\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 0.99\n",
      "Accuracy on the validation set: 0.73\n"
     ]
    }
   ],
   "source": [
    "pipline = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "pipline.fit(X_train, y_train)\n",
    "y_pred = pipline.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['Parents/Children Aboard', 'Parents/Children Aboard'], inplace=True)\n",
    "X_valid.drop(columns=['Parents/Children Aboard', 'Parents/Children Aboard'], inplace=True)\n",
    "X_test.drop(columns=['Parents/Children Aboard', 'Parents/Children Aboard'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 0.99\n",
      "Accuracy on the validation set: 0.70\n"
     ]
    }
   ],
   "source": [
    "pipline = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "pipline.fit(X_train, y_train)\n",
    "y_pred = pipline.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the result on validation set with removed features is worse. We will keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_valid, y_train_valid, test_size=0.1, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set: 0.68\n",
      "Accuracy on the validation set: 0.72\n"
     ]
    }
   ],
   "source": [
    "pipline_nv = make_pipeline(MultinomialNB(alpha=0.2, fit_prior=False))\n",
    "pipline_nv.fit(X_train, y_train)\n",
    "y_pred = pipline_nv.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline_nv.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1, 'fit_prior': True}\n",
      "Accuracy on the train set: 0.68\n",
      "Accuracy on the validation set: 0.72\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = MultinomialNB\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.2, 0.3],\n",
    "    'fit_prior': [True, False],\n",
    "}\n",
    "grid_search = GridSearchCV(model(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "pipline_nv = make_pipeline(model(**grid_search.best_params_))\n",
    "pipline_nv.fit(X_train, y_train)\n",
    "y_pred = pipline_nv.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline_nv.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy on the train set: 0.99\n",
      "Accuracy on the validation set: 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "}\n",
    "grid_search = GridSearchCV(model(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "pipline = make_pipeline(model(**grid_search.best_params_))\n",
    "pipline.fit(X_train, y_train)\n",
    "y_pred = pipline.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss', 'max_depth': 10, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Accuracy on the train set: 0.93\n",
      "Accuracy on the validation set: 0.75\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['random', 'best'],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "}\n",
    "grid_search = GridSearchCV(model(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "pipline = make_pipeline(model(**grid_search.best_params_))\n",
    "pipline.fit(X_train, y_train)\n",
    "y_pred = pipline.predict(X_valid)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, pipline.predict(X_train))\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred)\n",
    "print(f'Accuracy on the train set: {accuracy_train:.2f}')\n",
    "print(f'Accuracy on the validation set: {accuracy_valid:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid score:  0.8169014084507042\n",
      "Test score:  0.7303370786516854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"KNN\", KNeighborsClassifier(n_neighbors=7, p=1, weights=\"distance\")),\n",
    "        (\"Naive Bayes\", MultinomialNB(alpha=0.1, fit_prior=True)),\n",
    "        (\n",
    "            \"Decision tree\",\n",
    "            DecisionTreeClassifier(\n",
    "                criterion=\"log_loss\",\n",
    "                max_depth=5,\n",
    "                min_samples_split=4,\n",
    "                splitter=\"random\",\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "print(\"Valid score: \", ensemble.score(X_valid, y_valid))\n",
    "print(\"Test score: \", ensemble.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
