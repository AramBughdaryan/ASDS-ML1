{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYGbp2BJviXl"
   },
   "source": [
    "The deadline for this homework is on **28.11.2025 18:29** (right before the practice session). After completing the exercises, you should\n",
    "\n",
    "1. Download this file into your computer (`File` $\\to$ `Download .ipynb`)\n",
    "\n",
    "2. Name the file in the following way *HWx_NameSurname* (for example `HW1_NshanPotikyan.ipynb`)\n",
    "\n",
    "4. Submit the file via the e-learning environment.\n",
    "\n",
    "**Note**\n",
    "\n",
    "* if you do not follow any of the above conditions, your homework will not be graded.\n",
    "\n",
    "* you do not need to send any dataset files or helper scripts that I provide with your homework (since I already have them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsXZ3y2Dx9UM"
   },
   "source": [
    "**Problem.** During the practice session we tried to classify the titles of some news articles using the Naive Bayes algorithm with different data processing methods, but the result was not that good.\n",
    "\n",
    "* In this homework, you need to take the same dataset but this time you need to consider the article paragraph itself to train a classifier.\n",
    "\n",
    "* Split the training dataset into train/val parts, so that you can evaluate which data processing approach results in better performance.\n",
    "\n",
    "* Make use of sklearn [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline) to construct the different data processing pipelines.\n",
    "\n",
    "* Evaluate the model performance in terms of the accuracy score.\n",
    "\n",
    "* Use the best data processing method to train a final model on the train+val dataset and report the accuracy score on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwLldBkVzopd"
   },
   "source": [
    "Run the below command to download the train/test splits of the news dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "a-E4u0Nkvfbx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  145k  100  145k    0     0   2570      0 --:--:-- --:--:-- --:--:--     0k      0 --:--:-- --:--:-- --:--:--  257k\n",
      "Archive:  news_data.zip\n",
      "  inflating: train_news.csv          \n",
      "  inflating: test_news.csv           \n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/NshanPotikyan/Dasa1Doom/master/files/news_data.zip -o news_data.zip\n",
    "!unzip news_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "tSIs0T629eRy"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_news.csv')\n",
    "test = pd.read_csv('test_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w2IfNWt69edP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  209\n",
      "Validation dataset:  70\n"
     ]
    }
   ],
   "source": [
    "# train['article'] = train['article_title'] +'\\t' + train['article_paragraph']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train['article_paragraph'], train['type'], random_state = 0)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape[0])\n",
    "print(\"Validation dataset: \", X_val.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         209\n",
       "unique          2\n",
       "top       economy\n",
       "freq          105\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes_ensemble = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Baseline model on word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  0.9952153110047847\n",
      "Validation accuracy score:  1.0\n"
     ]
    }
   ],
   "source": [
    "pipe_freq = make_pipeline(CountVectorizer(stop_words='english'), MultinomialNB())\n",
    "pipe_freq.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_freq.predict(X_train)\n",
    "val_preds = pipe_freq.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use word frequencies with STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  1.0\n",
      "Validation accuracy score:  1.0\n"
     ]
    }
   ],
   "source": [
    "pipe_freq_no_sw = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_freq_no_sw.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_freq_no_sw.predict(X_train)\n",
    "val_preds = pipe_freq_no_sw.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_freq_no_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting on word occurrencies instead of frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  1.0\n",
      "Validation accuracy score:  0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "pipe_occur = make_pipeline(CountVectorizer(stop_words='english', binary=True), MultinomialNB())\n",
    "pipe_occur.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_occur.predict(X_train)\n",
    "val_preds = pipe_occur.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_occur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239     Armenian President Armen Sarkissian is in Syunik province on a two-day working visit, Armenpress correspondent reports from Meghri.Firstly, President Sarkissian visited the Meghri free economic zone, toured the area and got acquainted with the ongoing activities.Director of Meghri Free Economic Zone Ashot Zarbabyan said the Free Economic Zone has been established on December 15, 2017. At the moment they still face some problems, connected with lands and entry-exit regime. “As it is a border zone, entry and exit are certainly restricted, therefore, we face problems”, he said.The President asked whether these issues have not been discussed before 2017, whether they have not been solved before its launch, the staff of the Free Economic Zone stated that the project should have been implemented at two stages. The first stage was its launch and the next stage was to solve the remaining issues. The President was informed that a working group has been formed by the Prime Minister’s instru...\n",
      "Name: article_paragraph, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('max_colwidth', 1000):\n",
    "    print(X_val[y_val != val_preds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting on tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  0.9856459330143541\n",
      "Validation accuracy score:  0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "pipe_bernulli = make_pipeline(TfidfVectorizer(stop_words='english'), BernoulliNB())\n",
    "pipe_bernulli.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_bernulli.predict(X_train)\n",
    "val_preds = pipe_bernulli.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_bernulli)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that for this problemn MultiNomial NB works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  0.9952153110047847\n",
      "Validation accuracy score:  1.0\n"
     ]
    }
   ],
   "source": [
    "pipe_tf_idf = make_pipeline(TfidfVectorizer(stop_words='english'), MultinomialNB())\n",
    "pipe_tf_idf.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_tf_idf.predict(X_train)\n",
    "val_preds = pipe_tf_idf.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 2 grams with stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  1.0\n",
      "Validation accuracy score:  1.0\n"
     ]
    }
   ],
   "source": [
    "pipe_2gram = make_pipeline(CountVectorizer(stop_words='english', ngram_range=(1,2)), MultinomialNB())\n",
    "pipe_2gram.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_2gram.predict(X_train)\n",
    "val_preds = pipe_2gram.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_2gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 2 grams without stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score:  1.0\n",
      "Validation accuracy score:  0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "pipe_2gram_no_stop_words = make_pipeline(CountVectorizer(ngram_range=(1,2)), MultinomialNB())\n",
    "pipe_2gram_no_stop_words.fit(X_train, y_train)\n",
    "\n",
    "train_preds = pipe_2gram_no_stop_words.predict(X_train)\n",
    "val_preds = pipe_2gram_no_stop_words.predict(X_val)\n",
    "\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(\"Train accuracy score: \", accuracy_score(y_train, train_preds))\n",
    "print(\"Validation accuracy score: \", val_acc)\n",
    "\n",
    "if val_acc > 0.97:\n",
    "    pipes_ensemble.append(pipe_2gram_no_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.978494623655914\n",
      "Test Accuracy score:  0.978494623655914\n",
      "Test Accuracy score:  0.978494623655914\n",
      "Test Accuracy score:  0.978494623655914\n",
      "Test Accuracy score:  0.978494623655914\n",
      "Test Accuracy score:  0.978494623655914\n"
     ]
    }
   ],
   "source": [
    "for pipe in pipes_ensemble:\n",
    "    test_preds = pipe.predict(test['article_paragraph'])\n",
    "    print(\"Test Accuracy score: \", accuracy_score(test['type'], test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978494623655914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('pipe_freq', pipe_freq),\n",
    "    ('pipe_freq_no_sw', pipe_freq_no_sw),\n",
    "    ('pipe_occur', pipe_occur),\n",
    "    ('pipe_bernulli', pipe_bernulli),\n",
    "    ('pipe_tf_idf', pipe_tf_idf),\n",
    "    ('pipe_2gram', pipe_2gram),\n",
    "    ('pipe_2gram_no_stop_words', pipe_2gram_no_stop_words)\n",
    "])\n",
    "ensemble.fit(X_train, y_train)\n",
    "ensemble.score(test['article_paragraph'], test['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     article_title  \\\n",
      "61     Government to procure defense products from local manufacturers as priority   \n",
      "77  PM to hand over Hero Of Our Times prize for the first time on Independence Day   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          article_paragraph  \\\n",
      "61                                                                                                                                                                                                                                                                  After meeting representatives of the Armenian defense industry, PM Nikol Pashinyan briefed Cabinet members today on the agreements that have been reached.“We’ve agreed that we will very quickly inventorize those products of the military-industry sector which are being manufactured in Armenia. We will develop an approximate 5-year plan of the military’s demand, and we will work with the sector in two directions: the government will set an objective that procurements be made from local manufacturers if the latter will display concrete actions aimed at increasing their productivity and lowering costs and a roadmap,” the PM said.PM Pashinyan tasked the Cabinet to regularly brief him on the matter.Edited and translated by Stepan Kocharyan   \n",
      "77   The Armenian Prime Minister will hand for the first time the Hero Of Our Times prize within the frames of the celebrations dedicated to 28th anniversary of the Republic of Armenia.Chief of the PM’s staff Eduard Aghajanyan told reporters during today’s press conference that the award will be handed over to a person who established his own business and linked his future with Armenia.“This year for the first time the award titled the Hero Of Our Times will be held on September 21 which will be attended by people who change their life or that of the others, run a business on their own and link their future with Armenia. The participants of the first award ceremony will be the heroes of the Hero Of Our Times program in the past one year. During the event the officials and guests will hand over prizes to the heroes, but the main prize will be the prize of the PM”, he said.Aghajanyan added that with such an event on the Independence Day the state shows that it praises its citizens and hi...   \n",
      "\n",
      "        type  \n",
      "61  military  \n",
      "77   economy  \n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('max_colwidth', 1000):\n",
    "    print(test[test['type'] != test_preds])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
